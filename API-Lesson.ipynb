{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ff6db3-807e-45f6-8747-d7279d81f225",
   "metadata": {},
   "source": [
    "# APIs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e9e19-4ecd-433f-a6f7-e051d0cf2cac",
   "metadata": {},
   "source": [
    "## 1. Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8dae1-b370-49d7-a65e-d4c32c5b2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a6936-5f20-4391-ad22-e11e843b7350",
   "metadata": {},
   "source": [
    "## 2. Get a Google Maps API Key\n",
    "\n",
    "Some parts of this project require a **Google Maps API key**.\n",
    "\n",
    "### Step 1: Create a Google Cloud Project\n",
    "1. Go to:  \n",
    "   https://console.cloud.google.com/\n",
    "2. Sign in with your Google account.\n",
    "3. Create a **new project** (or select an existing one).\n",
    "\n",
    "### Step 2: Enable the Places API\n",
    "1. In the Google Cloud Console, go to **APIs & Services → Library**.\n",
    "2. Search for **Places API** (or Nearby Search API).\n",
    "3. Click **Enable**.\n",
    "\n",
    "### Step 3: Create an API Key\n",
    "1. Go to **APIs & Services → Credentials**.\n",
    "2. Click **Create Credentials → API Key**.\n",
    "3. Copy your API key and keep it private.\n",
    "\n",
    "> **Important:** Google may require billing information, but the free tier is sufficient for this lesson.\n",
    "\n",
    "### Retrieving Existing API Key\n",
    "1. Go to **APIs & Services → Credentials**.\n",
    "2. Click **Show Key**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba79ef2d-e8ed-4bc7-8227-8942b3ac2128",
   "metadata": {},
   "source": [
    "## 3. Copy Your API Key into this string\n",
    "If you plan to publish code using APIs do **not** include your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597d846-b558-43c3-850d-6794a52accb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fca4f5-984b-4342-9b00-9b383bb369d2",
   "metadata": {},
   "source": [
    "## 4. Searching Restaurants Given a Location\n",
    "The following code block gets data for restaurants given a location and radius.\n",
    "Notes:\n",
    "- The first 2 lines define the location in longitude and latitude coordinates and the radius in meters from that point where our search will take place\n",
    "- Each request is capped at 20 restaurants, for the sake of this excercise this is sufficient\n",
    "- The output is a json file, we will learn more about reading json files later in this notebook\n",
    "- The name of the output file includes the date and time. This was added to prevent accidentally overriding data as every time the code runs it would produce a file with a unique name. This is up to the user's preference and can be changed.\n",
    "\n",
    "### Note\n",
    "Do not run the code over and over again excessively, there are limits to the amount of times you can use the API before being charged (about 6,000 requests per month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b382136-3429-4f74-b25b-6a0ec82b2b7d",
   "metadata": {},
   "source": [
    "### Coordinates of Major Cities\n",
    "\n",
    "| City               | Latitude  | Longitude   |\n",
    "|-------------------|----------|------------|\n",
    "| New York, NY       | 40.7128  | -74.0060   |\n",
    "| Los Angeles, CA    | 34.0522  | -118.2437  |\n",
    "| Chicago, IL        | 41.8781  | -87.6298   |\n",
    "| Honolulu, HI       | 21.3069  | -157.8583  |\n",
    "| Miami, FL          | 25.7617  | -80.1918   |\n",
    "| Houston, TX        | 29.7604  | -95.3698   |\n",
    "| Seattle, WA        | 47.6062  | -122.3321  |\n",
    "| Boston, MA         | 42.3601  | -71.0589   |\n",
    "| Denver, CO         | 39.7392  | -104.9903  |\n",
    "| San Francisco, CA  | 37.7749  | -122.4194  |\n",
    "| Indianapolis, IN   | 39.7684  | -86.1581   |\n",
    "| Phoenix, AZ        | 33.4484  | -112.0740  |\n",
    "| Des Moines, IA     | 41.5868  | -93.6250   |\n",
    "| Columbus, OH       | 39.9612  | -82.9988   |\n",
    "| Hartford, CT       | 41.7658  | -72.6734   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd6805-3f28-4a0d-b8a8-b91921b5f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input() makes a text box that the user can input a value\n",
    "latitude = input('Input your latitude coordinate (example 40.7644): ')\n",
    "longitude  = input('Input your longitude  coordinate (example -73.9184): ')\n",
    "LOCATION = str(latitude)+','+str(longitude)\n",
    "RADIUS = 2000  # in meters, feel free to change this too\n",
    "\n",
    "# Using the API\n",
    "url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={LOCATION}&radius={RADIUS}&type=restaurant&key={API_KEY}\"\n",
    "response = requests.get(url)\n",
    "restaurants = response.json().get('results', [])\n",
    "\n",
    "# This part creates the file name with the time stamp. Feel free to change this if you would like.\n",
    "# Important - make sure your filename ends in .json\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "filename = f'restaurants_{timestamp}.json'\n",
    "   \n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(restaurants, f, indent=2)\n",
    "    \n",
    "print(f\"Saved {len(restaurants)} restaurants to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fc420-0147-4245-a875-a0c4efc06783",
   "metadata": {},
   "source": [
    "#### Check\n",
    "Now let's check to see if `restaurants` has stored our data.\n",
    "We should also check the folder this file is in to see if the file was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ee968-22b2-4cd7-96b9-b360cc56a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the type of our, it should be a list\n",
    "type(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875da97-9e90-4641-a8d3-ca6154c1c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming it is a list, let's look at the first element\n",
    "print(f\"This should be a dictionary: {type(restaurants[0])}\")\n",
    "restaurants[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716153f-f53d-4565-bddc-09739cfe9e2c",
   "metadata": {},
   "source": [
    "#### Result\n",
    "The above code should produce something like this\n",
    "\n",
    "{'business_status': 'OPERATIONAL',<br>\n",
    " 'geometry': {'location': {'lat': 40.7555621, 'lng': -73.9224658},<br>\n",
    "  'viewport': {'northeast': {'lat': 40.7569783802915,<br>\n",
    "    'lng': -73.9213070197085},<br>\n",
    "...\n",
    "}\n",
    "\n",
    "You can also check the other elements of `restuarants` follow a similar format.\n",
    "\n",
    "We will go further into analyzing the data later in the lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ed352-430c-4e9c-83b1-674d9f955aba",
   "metadata": {},
   "source": [
    "#### Reading Files\n",
    "The output said that our data was saved to a .json file. Let's practice reading json files\n",
    "\n",
    "This cell should output a list of dictionaries similar to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c683d40-6064-4308-88b4-a79f06123bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"example_file.json\" # You can replace this with your file name\n",
    "with open(file_name) as f:\n",
    "    data_from_json = json.load(f)\n",
    "data_from_json[0] #You can change this to look at different elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c420722b-e772-4b1f-b4f3-b0a51421e2d9",
   "metadata": {},
   "source": [
    "## 5. Getting Coordinates from a Zip Code\n",
    "The above code is dependent on having the longitude and latitude coordinates for the center of your search. Often times, we may not have that but instead have a zip code. We can get longitude and latitude coordinates from a zip code using Google's Geocoding API.\n",
    "\n",
    "We first need to enable it using the following steps:\n",
    "- Go to https://console.cloud.google.com/\n",
    "- Make sure the correct project is selected (top bar).\n",
    "- Navigate to APIs & Services → Library\n",
    "- Search for Geocoding API\n",
    "- Click Enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77b7c9-5bca-4e2c-a97b-612ca91dd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_CODE = \"10001\" # You can change this\n",
    "\n",
    "url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={ZIP_CODE}&key={API_KEY}\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "if data['results']:\n",
    "    location = data['results'][0]['geometry']['location']\n",
    "    lat = location['lat']\n",
    "    lng = location['lng']\n",
    "    print(f\"Coordinates for {ZIP_CODE}: {round(lat,3)}, {round(lng,3)}\")\n",
    "else:\n",
    "    print(\"No results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1cd082-e353-4d36-814e-ced5f33702c7",
   "metadata": {},
   "source": [
    "## 6. Getting Data from a Specific Address\n",
    "Suppose we wanted to get rating data for a policy we plan to write or have already written. We would probably already have the address and name of the business. Let's get data from the API given a list of specific locations.\n",
    "\n",
    "#### Note\n",
    "When looking up restaurants and other businesses, the API works better if you put the name of the business in the search rather than the building number. This is because the API is designed to search for prominent locations which are primarily identified by their unique names rather than just raw address data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895d04e-8236-4336-a87e-fe54fd7fa6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addresses that we will be testing. Feel free to add and/or remove items\n",
    "addresses = [\n",
    "    \"Gino’s Pizzeria and Restaurant Astoria, NY 11103\",\n",
    "    \"Applebee's Grill + Bar 35th Avenue, Astoria, NY 11101\",\n",
    "    \"DiWine Natural Wine Bar & Restaurant, Astoria, NY 11103\",\n",
    "    \"Spyce Astoria, Astoria, NY 11103\",\n",
    "    \"German Doner Kebab Steinway St, Astoria, NY 11103\",\n",
    "    \"Chuck E. Cheese 48th Street, Long Island City\"\n",
    "]\n",
    "MAX_PHOTOS = 3  # cap number of images per location\n",
    "\n",
    "def get_place_data(address):\n",
    "    '''\n",
    "    This function returns a place id from an address. The address must be a string.\n",
    "    '''\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
    "    params = {\n",
    "        \"input\": address,\n",
    "        \"inputtype\": \"textquery\",\n",
    "        \"fields\": \"place_id\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def get_place_details(place_id):\n",
    "    '''\n",
    "    Returns detailed place information given a place_id.\n",
    "    Includes fields useful for insurance pricing and risk assessment.\n",
    "    '''\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "    params = {\n",
    "        \"place_id\": place_id,\n",
    "        \"fields\": (\n",
    "            \"name,\"\n",
    "            \"formatted_address,\"\n",
    "            \"types,\"\n",
    "            \"price_level,\"\n",
    "            \"rating,\"\n",
    "            \"user_ratings_total,\"\n",
    "            \"business_status,\"\n",
    "            \"reviews,\"\n",
    "            \"photos,\"\n",
    "            \"website,\"\n",
    "            \"international_phone_number,\"\n",
    "            \"opening_hours,\"\n",
    "            \"geometry,\"\n",
    "            \"vicinity,\"\n",
    "            \"plus_code\"\n",
    "        ),\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json().get(\"result\", {})\n",
    "\n",
    "\n",
    "def build_photo_urls(photos, maxwidth=400, max_photos=MAX_PHOTOS):\n",
    "    '''\n",
    "    Convert photo references into usable image URLs\n",
    "    '''\n",
    "    urls = []\n",
    "    for p in photos[:max_photos]:  # cap applied here\n",
    "        ref = p.get(\"photo_reference\")\n",
    "        if ref:\n",
    "            urls.append(\n",
    "                \"https://maps.googleapis.com/maps/api/place/photo\"\n",
    "                f\"?maxwidth={maxwidth}&photo_reference={ref}&key={API_KEY}\"\n",
    "            )\n",
    "    return urls\n",
    "\n",
    "results = []\n",
    "\n",
    "for addr in addresses:\n",
    "    print(f\"Searching: {addr}\")\n",
    "\n",
    "    data = get_place_data(addr)\n",
    "    candidates = data.get(\"candidates\", [])\n",
    "\n",
    "    if candidates:\n",
    "        place_id = candidates[0][\"place_id\"]\n",
    "        details = get_place_details(place_id)\n",
    "\n",
    "        photos = details.get(\"photos\", [])\n",
    "        details[\"photo_urls\"] = build_photo_urls(photos)\n",
    "\n",
    "        results.append(details)\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "\n",
    "    time.sleep(0.2)  # Respect rate limits\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "filename = f\"restaurants_by_address_{timestamp}.json\"\n",
    "\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(results)} restaurants to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1d0d1-c269-4201-968f-1b0b7d0f78fb",
   "metadata": {},
   "source": [
    "### Check\n",
    "Let's see if our data pull worked as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea10359-78fa-4da8-9c1f-4d9f590bd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data from the first item in the list\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67ee03-b54e-476c-a32a-90a5857c34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the fields that item has\n",
    "list(results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7a83b-6ee2-4dbb-9279-243d7adde4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look at the images using IPython's Image and display functions\n",
    "def display_photo(url, maxwidth=600):\n",
    "    response = requests.get(url)\n",
    "    display(Image(data=response.content))\n",
    "\n",
    "# Assuming you pulled data for n restaurants, make this a number 0 to n-1\n",
    "restaurant_number = 1\n",
    "print(results[restaurant_number]['name'])\n",
    "for i in range(len(results[restaurant_number]['photo_urls'])):\n",
    "    display_photo(results[restaurant_number]['photo_urls'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee40fec-c9fa-4afa-9c8f-34c42ad1280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look more into reviews\n",
    "print(len(results[0]['reviews']))\n",
    "results[0]['reviews'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac0f9e-996d-4ba9-948e-953fe127d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the formatting\n",
    "restaurant_number = 3\n",
    "print(results[restaurant_number]['name'])\n",
    "print()\n",
    "for i in range(len(results[restaurant_number]['reviews'])):\n",
    "    print(results[restaurant_number]['reviews'][i]['author_name'])\n",
    "    print(str(results[restaurant_number]['reviews'][i]['rating'])+'/5')\n",
    "    print(results[restaurant_number]['reviews'][i]['text'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e62605-4215-4f71-b0f3-88c2329069a4",
   "metadata": {},
   "source": [
    "## 7. Cleaning and Interpreting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694f244-0796-4877-9920-b7bca93ce5de",
   "metadata": {},
   "source": [
    "We have now been over multiple ways of pulling data from the API.\n",
    "\n",
    "We will now go over methods to make our data easier to understand and use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f3ab6-7150-4334-935c-b18d0ad84e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pick one of the json files you made in the code above\n",
    "# You can also use the pre-made example file\n",
    "file_name = 'example_file_detailed.json'\n",
    "with open(file_name) as f:\n",
    "    data_from_json = json.load(f)\n",
    "data_from_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5ad1a-d9a4-4c8e-af49-f95fd07f9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to make sure our data types are all right\n",
    "print(f\"This should be a list: {type(data_from_json)}\")\n",
    "print(f\"This should be a dict: {type(data_from_json[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c1bf3-442e-465f-841e-dcd65e5f8e7b",
   "metadata": {},
   "source": [
    "## 8. Cleaning Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a874a-6b4b-44de-a4e6-9d7480915a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can convert our data from the list of dictionaries to a dataframe\n",
    "pd.DataFrame(data=data_from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d1e01-feb7-4aec-a0ae-b928524549eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save the dataframe as df\n",
    "df = pd.DataFrame(data=data_from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2081e3-7abf-4ab1-8665-d2300024800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b38fe5-373d-4e84-b604-923e85bc5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's move the 'name' column to be the first in the list\n",
    "columns_without_name = [c for c in df.columns if c!='name'] #all columns besides name in the same order\n",
    "reordered_columns = ['name']+columns_without_name # name and then all other columns\n",
    "df = df[reordered_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acf29d-3ca0-4155-84a2-b890428b0ea1",
   "metadata": {},
   "source": [
    "### Flattening Dictionaries\n",
    "Some of our columns have data stored as dictionaries. Some of these dictionaries have dictionaries inside of them. Let's separate the data by column and key to make the data more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d17ec-a543-4fcb-922a-889050e857e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key=\"\"):\n",
    "    \"\"\"\n",
    "    Convert a nested dictionary into a single-level dictionary.\n",
    "\n",
    "    This function takes a dictionary that may contain other dictionaries\n",
    "    as values and \"flattens\" it so that there are no nested dictionaries.\n",
    "    The keys from inner dictionaries are combined with their parent keys\n",
    "    using underscores.\n",
    "\n",
    "    Example:\n",
    "        Input:\n",
    "            {\"geometry\": {\"location\": {\"lat\": 40.7,\"lng\": -73.9}}}\n",
    "\n",
    "        Output:\n",
    "            {\n",
    "                \"geometry_location_lat\": 40.7,\n",
    "                \"geometry_location_lng\": -73.9\n",
    "            }\n",
    "\n",
    "    Parameters:\n",
    "        d (dict):\n",
    "            The dictionary to flatten. It may contain nested dictionaries.\n",
    "        parent_key (str):\n",
    "            Used internally during recursion to build up the full key name.\n",
    "            When calling the function yourself, you should not set this.\n",
    "    \"\"\"\n",
    "    items = {}\n",
    "\n",
    "    # Loop through each key-value pair in the dictionary\n",
    "    for k, v in d.items():\n",
    "        # Create a new key name.\n",
    "        # If we are inside a nested dictionary, prepend the parent key.\n",
    "        # Otherwise, just use the current key.\n",
    "        new_key = f\"{parent_key}_{k}\" if parent_key else k\n",
    "\n",
    "        # If the value is another dictionary, flatten it recursively\n",
    "        if isinstance(v, dict):\n",
    "            # Flatten the inner dictionary and add it to the items\n",
    "            items.update(flatten_dict(v, new_key))\n",
    "        else:\n",
    "            # If the value is not a dictionary, store it directly\n",
    "            items[new_key] = v\n",
    "    return items\n",
    "\n",
    "\n",
    "df_expanded = df.copy()\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "        flattened = df[col].apply(lambda x: flatten_dict(x) if isinstance(x, dict) else {})\n",
    "        new_cols = pd.json_normalize(flattened).add_prefix(f\"{col}_\")\n",
    "        df_expanded = pd.concat([df_expanded, new_cols], axis=1)\n",
    "\n",
    "\n",
    "df = df_expanded.drop(\n",
    "    columns=[col for col in df.columns if df[col].apply(lambda x: isinstance(x, dict)).any()] # Remove the columns with dictionaries in them\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953baf4-1515-4ee5-816f-26eb98efa7f4",
   "metadata": {},
   "source": [
    "### Unique Values\n",
    "Columns that only have 1 unique value are most likely not useful. Let's write code to see the columns with only 1 unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c9a4d-ec32-41f3-bc35-ba65bdbbbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the number of unique values per column\n",
    "for col in df.columns:\n",
    "    print()\n",
    "    uniques = set(df[col].astype(str))\n",
    "    print(f\"{col}: {len(uniques)}\")\n",
    "    if(len(uniques)==1):\n",
    "        print('UNIQUE VALUE: '+str(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd582095-0ee4-4cb9-af39-528c865b2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['opening_hours_open_now']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4b1f0-6b7c-4e9d-a5e8-e6f89d925e8a",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cacc8a-79a8-41ec-82ef-1028deb969a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "df = df.drop(columns=['opening_hours_open_now','geometry_viewport_northeast_lat',\n",
    "                      'geometry_viewport_northeast_lng','geometry_viewport_southwest_lat',\n",
    "                      'geometry_viewport_southwest_lng','opening_hours_open_now','plus_code_compound_code',\n",
    "                     'plus_code_global_code']) \n",
    "# Feel free to add or change this\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fb645-e4d8-48e1-b885-836a873dbce8",
   "metadata": {},
   "source": [
    "### Making Binary Variables for `types`\n",
    "`types` is a column in our dataset containing a list of descriptors for the establishment.\n",
    "\n",
    "For each descriptor, we can make a binary variable equal to `1` if the establishment contains the descriptor and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46eed3-5773-48cc-8d41-e86444a67b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's find all unique values within the types\n",
    "unique_types = set()\n",
    "for sublist in df['types']:\n",
    "    unique_types = unique_types | set(sublist) # This is the union of 2 sets\n",
    "unique_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef2b8d-48b8-4a49-ac1c-f8cbfc9124ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for restaurant_type in unique_types:\n",
    "    binary_values = []\n",
    "    for type_list in df['types']:\n",
    "        if(restaurant_type in type_list):\n",
    "            binary_values.append(1)\n",
    "        else:\n",
    "            binary_values.append(0)\n",
    "    df[restaurant_type] = binary_values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2835769-76db-4681-b683-dc6980b440b4",
   "metadata": {},
   "source": [
    "### Making Binary Columns Based on Reviews\n",
    "The presence of certain words in a review can be an indicator.\n",
    "\n",
    "If the review has the words `\"rats\"`, `\"mold\"`, or `\"dirty\"`, it can be a sign that the premises is dirty.\n",
    "\n",
    "Our API only takes the 5 top reviews. We can say that if a key word is present in multiple reviews, we can set the indicator to `1`.\n",
    "\n",
    "We can use the review score to determine negative sentiment to make our search more refined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ffc5d-e079-4f75-8bd1-635a7ef67225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords\n",
    "cleanliness_keywords = ['rats','roaches','mold','dirty','dirt','filthy','bugs','flies','odor','grease','grime','unsanitary','sticky','stains']\n",
    "food_safety_keywords = ['food poisoning','sick','vomiting','diarrhea','undercooked','raw','spoiled','expired','bad food','stale','nauseous','ache','stomach']\n",
    "safety_security_keywords = ['unsafe','dangerous','fight','fighting','assault','aggressive','threatening','stolen','theft','robbery','security','police','crime']\n",
    "slip_fall_keywords = ['slipped and fell','slip and fall','fell on the floor','wet floor','no wet floor sign','slippery floor','uneven floor','broken tile','loose tile','stairs without railing','no handrail']\n",
    "\n",
    "# These will be populated with 1s and 0s as we loop through each restaurant\n",
    "cleanliness_binary = []\n",
    "food_safety_binary = []\n",
    "safety_binary = []\n",
    "slip_fall_binary = []\n",
    "\n",
    "review_number_theshold = 2 # 2 or more that get flagged make the binary 1\n",
    "minimum_review_rating = 3 # If the rating is above a 3, the review is most likely not negative\n",
    "\n",
    "# Each restaurant has a list of reviews\n",
    "for review_list in df['reviews']:\n",
    "    # How many restaurants were flagged for each type of flag\n",
    "    clean_flag = 0\n",
    "    food_safety_flag = 0\n",
    "    safe_flag = 0\n",
    "    slip_flag = 0\n",
    "    \n",
    "    for review in review_list:\n",
    "        if(review['rating']<=minimum_review_rating and max([c in review['text'].lower() for c in cleanliness_keywords])):\n",
    "            clean_flag += 1\n",
    "        if(review['rating']<=minimum_review_rating and max([c in review['text'].lower() for c in food_safety_keywords])):\n",
    "            food_safety_flag += 1\n",
    "        if(review['rating']<=minimum_review_rating and max([c in review['text'].lower() for c in safety_security_keywords])):\n",
    "            safe_flag += 1\n",
    "        if(review['rating']<=minimum_review_rating and max([c in review['text'].lower() for c in slip_fall_keywords])):\n",
    "            slip_flag += 1\n",
    "\n",
    "    # If 2 or more are flagged, append 1, otherwise append 0\n",
    "    if(clean_flag>=2):\n",
    "        cleanliness_binary.append(1)\n",
    "    else:\n",
    "        cleanliness_binary.append(0)\n",
    "\n",
    "    if(food_safety_flag>=2):\n",
    "        food_safety_binary.append(1)\n",
    "    else:\n",
    "        food_safety_binary.append(0)\n",
    "\n",
    "    if(safe_flag>=2):\n",
    "        safety_binary.append(1)\n",
    "    else:\n",
    "        safety_binary.append(0)\n",
    "\n",
    "    if(slip_flag>=2):\n",
    "        slip_fall_binary.append(1)\n",
    "    else:\n",
    "        slip_fall_binary.append(0)\n",
    "\n",
    "# Put the binary lists in the dataframe\n",
    "df['Unclean_Flag'] = cleanliness_binary\n",
    "df['Food_Safety_Flag'] = food_safety_binary\n",
    "df['Crime_Flag'] = safety_binary\n",
    "df['Slip_Flag'] = slip_fall_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d2691-2381-4834-ab40-6581cab61a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9af01-c458-4096-aff5-9558d960f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('output.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
